# Monocular Depth Training Configuration for OnlineDataLoader
# Reference: https://github.com/grasp-lyrl/fast-feature-fields/blob/main/confs/monocular_depth/dav2b_fullttairv2indoor_pseudo_308x308x20.yml

# Training options
lr: 6.0e-6 # Learning rate
lr_end_factor: 1.0 # Learning rate decay (linear scheduler end factor)
clip_grad: 0 # Gradient clipping (0 = disabled)
epochs: 1000 # Number of epochs
log_interval: 10 # Save checkpoint interval in epochs
val_interval: 10 # Validation interval in epochs

# Event options
polarity: [False, False] # [use_polarity_ctx, use_polarity_pred]

# Training data options
train:
  batch: 8 # Effective batch size
  mini_batch: 8 # Mini batch size per forward pass

# Loss options
loss: ssimae # Loss function: 'ssimae', 'silog', 'siloggrad'
scales: 4 # Number of scales for gradient matching loss
alpha: 0.3 # Weight for gradient matching loss
min_disparity: 0.05 # Minimum disparity for max depth 20.0 m
max_disparity: 1000.0 # Maximum disparity for min depth 0.001 m

# DepthAnythingV2 config
dav2_config:
  size: 308 # Input size for DAv2
  encoder: vitb # Encoder type: 'vits', 'vitb', 'vitl'
  ckpt: applications/f3_training/models/depth_anything_v2_vitb.pth # Path to DAv2 checkpoint

# EventFF (F3) config - the feature backbone
eventff:
  config: deps/fast-feature-fields/confs/ff/modeloptions/640x480x20_patchff_ds1_small_v1.yml
  ckpt: applications/f3_training/models/640x480x20_patchff_ds1_small_v1.pth # Path to EventFF checkpoint

# OnlineDataLoader settings
dataloader:
  dataset_config: "configs/example_dataset_config.yaml" # Path to dataset config
  event_sensor: "event_camera_1" # UUID of event sensor
  depth_sensor: "depth_camera_1" # UUID of depth sensor
  color_sensor: "color_camera_1" # UUID of color sensor (used for visualization)
  queue_maxsize: 1000
  max_events: 8_000_000
  prefetch_factor: 8
